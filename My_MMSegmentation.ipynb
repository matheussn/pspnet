{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83acaa9d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83acaa9d",
    "outputId": "b04c0098-12b9-48b2-bf88-7956abbb75f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.8.1+cu101 in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (1.8.1+cu101)\n",
      "Requirement already satisfied: torchvision==0.9.1+cu101 in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (0.9.1+cu101)\n",
      "Requirement already satisfied: typing-extensions in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from torch==1.8.1+cu101) (4.0.1)\n",
      "Requirement already satisfied: numpy in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from torch==1.8.1+cu101) (1.21.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from torchvision==0.9.1+cu101) (8.4.0)\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu101/torch1.8.0/index.html\n",
      "Requirement already satisfied: mmcv-full in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (1.4.1)\n",
      "Requirement already satisfied: opencv-python>=3 in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from mmcv-full) (4.5.4.60)\n",
      "Requirement already satisfied: pyyaml in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from mmcv-full) (6.0)\n",
      "Requirement already satisfied: packaging in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from mmcv-full) (21.3)\n",
      "Requirement already satisfied: addict in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from mmcv-full) (2.4.0)\n",
      "Requirement already satisfied: Pillow in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from mmcv-full) (8.4.0)\n",
      "Requirement already satisfied: numpy in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from mmcv-full) (1.21.4)\n",
      "Requirement already satisfied: yapf in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from mmcv-full) (0.31.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from packaging->mmcv-full) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch\n",
    "!pip install -U torch==1.8.1+cu101 torchvision==0.9.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# Install MMCV\n",
    "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.8.0/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df0f9312",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df0f9312",
    "outputId": "1ad43423-3199-4179-c71a-07485cdb46ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mmsegmentation'...\n",
      "remote: Enumerating objects: 5609, done.\u001b[K\n",
      "remote: Counting objects: 100% (117/117), done.\u001b[K\n",
      "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
      "remote: Total 5609 (delta 50), reused 63 (delta 33), pack-reused 5492\u001b[K\n",
      "Receiving objects: 100% (5609/5609), 11.57 MiB | 13.19 MiB/s, done.\n",
      "Resolving deltas: 100% (4118/4118), done.\n",
      "/home/neto/projects/tcc/mmsegmentation\n",
      "Obtaining file:///home/neto/projects/tcc/mmsegmentation\n",
      "Requirement already satisfied: matplotlib in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from mmsegmentation==0.20.2) (3.5.1)\n",
      "Requirement already satisfied: numpy in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from mmsegmentation==0.20.2) (1.21.4)\n",
      "Requirement already satisfied: packaging in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from mmsegmentation==0.20.2) (21.3)\n",
      "Requirement already satisfied: prettytable in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from mmsegmentation==0.20.2) (2.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from matplotlib->mmsegmentation==0.20.2) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from matplotlib->mmsegmentation==0.20.2) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from matplotlib->mmsegmentation==0.20.2) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from matplotlib->mmsegmentation==0.20.2) (3.0.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from matplotlib->mmsegmentation==0.20.2) (4.28.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from matplotlib->mmsegmentation==0.20.2) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->mmsegmentation==0.20.2) (1.16.0)\n",
      "Requirement already satisfied: wcwidth in /home/neto/anaconda3/envs/torch_gpu/lib/python3.9/site-packages (from prettytable->mmsegmentation==0.20.2) (0.2.5)\n",
      "Installing collected packages: mmsegmentation\n",
      "  Running setup.py develop for mmsegmentation\n",
      "Successfully installed mmsegmentation-0.20.2\n"
     ]
    }
   ],
   "source": [
    "!rm -rf mmsegmentation\n",
    "!git clone https://github.com/open-mmlab/mmsegmentation.git \n",
    "%cd mmsegmentation\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d007b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52d007b4",
    "outputId": "bc5f95c6-ee75-4890-9324-9b0a70ce63ad"
   },
   "outputs": [],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMSegmentation installation\n",
    "import mmseg\n",
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "from mmseg.apis import set_random_seed, train_segmentor\n",
    "from mmseg.models import build_segmentor\n",
    "print(mmseg.__version__)\n",
    "\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9059039b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9059039b",
    "outputId": "d4c7dc82-f5c0-4c27-9412-f2c2c416d165"
   },
   "outputs": [],
   "source": [
    "!unzip ../segmentationV2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aaf774",
   "metadata": {
    "id": "24aaf774"
   },
   "outputs": [],
   "source": [
    "data_root = 'segmentation'\n",
    "img_dir = 'images'\n",
    "ann_dir = 'annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443efdad",
   "metadata": {
    "id": "443efdad"
   },
   "outputs": [],
   "source": [
    "classes = ('bg', 'cell')\n",
    "palette = [[0, 0, 0], [255, 255, 255]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf908c98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "cf908c98",
    "outputId": "6ed582f4-7226-4458-d42c-107bff85ef4f"
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the segmentation map we got\n",
    "\n",
    "img = Image.open('segmentation/annotations/image003-2-roi1.jpg')\n",
    "plt.figure(figsize=(8, 6))\n",
    "im = plt.imshow(np.array(img.convert('RGB')))\n",
    "\n",
    "# create a patch (proxy artist) for every color \n",
    "patches = [mpatches.Patch(color=np.array(palette[i])/255., \n",
    "                          label=classes[i]) for i in range(2)]\n",
    "# put those patched as legend-handles into the legend\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., \n",
    "           fontsize='large')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e418cf76",
   "metadata": {
    "id": "e418cf76"
   },
   "outputs": [],
   "source": [
    "# split train/val set randomly\n",
    "split_dir = 'splits'\n",
    "mmcv.mkdir_or_exist(osp.join(data_root, split_dir))\n",
    "filename_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(osp.join(data_root, ann_dir), suffix='.jpg')]\n",
    "with open(osp.join(data_root, split_dir, 'train.txt'), 'w') as f:\n",
    "    # select first 4/5 as train set\n",
    "    train_length = int(len(filename_list)*4/5)\n",
    "    f.writelines(line + '\\n' for line in filename_list[:train_length])\n",
    "with open(osp.join(data_root, split_dir, 'val.txt'), 'w') as f:\n",
    "    # select last 1/5 as train set\n",
    "    f.writelines(line + '\\n' for line in filename_list[train_length:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96138cd",
   "metadata": {
    "id": "b96138cd"
   },
   "outputs": [],
   "source": [
    "@DATASETS.register_module()\n",
    "class TestDataSetResize(CustomDataset):\n",
    "    CLASSES = classes\n",
    "    PALETTE = palette\n",
    "    def __init__(self, split, **kwargs):\n",
    "        super().__init__(img_suffix='.jpg', seg_map_suffix='.jpg', split=split, **kwargs)\n",
    "        assert osp.exists(self.img_dir) and self.split is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b26b02a",
   "metadata": {
    "id": "9b26b02a"
   },
   "outputs": [],
   "source": [
    "cfg = Config.fromfile('configs/unet/fcn_unet_s5-d16_4x4_512x1024_160k_cityscapes.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc4bcf0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddc4bcf0",
    "outputId": "58afec43-d26f-4de1-ec23-5c01b29e7d96"
   },
   "outputs": [],
   "source": [
    "# Since we use ony one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "cfg.model.pretrained = None\n",
    "\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "# cfg.model.backbone.depth = 18\n",
    "\n",
    "# cfg.model.decode_head.in_channels = 250\n",
    "# cfg.model.decode_head.channels = 128\n",
    "\n",
    "# cfg.model.auxiliary_head.in_channels = 450\n",
    "# cfg.model.auxiliary_head.in_channels = 112\n",
    "\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 2\n",
    "cfg.model.auxiliary_head.num_classes = 2\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'TestDataSetResize'\n",
    "cfg.data_root = data_root\n",
    "\n",
    "cfg.data.samples_per_gpu = 1\n",
    "cfg.data.workers_per_gpu = 1\n",
    "\n",
    "cfg.img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "cfg.crop_size = (256, 256)\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(320, 240), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(320, 240),\n",
    "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "\n",
    "cfg.data.train = dict(\n",
    "    type=cfg.dataset_type,\n",
    "    data_root=data_root,\n",
    "    img_dir=img_dir,\n",
    "    ann_dir=ann_dir,\n",
    "    pipeline = cfg.train_pipeline,\n",
    "    split = 'splits/train.txt'\n",
    ")\n",
    "\n",
    "# cfg.data.train.type = cfg.dataset_type\n",
    "# cfg.data.train.data_root = data_root\n",
    "# cfg.data.train.img_dir = img_dir\n",
    "# cfg.data.train.ann_dir = ann_dir\n",
    "# cfg.data.train.pipeline = cfg.train_pipeline\n",
    "# cfg.data.train.split = 'splits/train.txt'\n",
    "\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "cfg.data.val.data_root = data_root\n",
    "cfg.data.val.img_dir = img_dir\n",
    "cfg.data.val.ann_dir = ann_dir\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "cfg.data.val.split = 'splits/val.txt'\n",
    "\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "cfg.data.test.data_root = data_root\n",
    "cfg.data.test.img_dir = img_dir\n",
    "cfg.data.test.ann_dir = ann_dir\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "cfg.data.test.split = 'splits/val.txt'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './work_dirs/tutorial'\n",
    "\n",
    "cfg.runner.max_iters = 200\n",
    "cfg.log_config.interval = 10\n",
    "cfg.evaluation.interval = 200\n",
    "cfg.checkpoint_config.interval = 200\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932fee98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "932fee98",
    "outputId": "a1260b96-1a16-4497-95e3-6ea3df1f6326"
   },
   "outputs": [],
   "source": [
    "datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e740d93b",
   "metadata": {
    "id": "e740d93b"
   },
   "outputs": [],
   "source": [
    "# Build the detector\n",
    "model = build_segmentor(\n",
    "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af36ee7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7af36ee7",
    "outputId": "e2af0c2a-716e-42e1-8772-3ff19e192e2a"
   },
   "outputs": [],
   "source": [
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_segmentor(model, datasets, cfg, distributed=False, validate=True, meta=dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d01d86b",
   "metadata": {
    "id": "3d01d86b"
   },
   "outputs": [],
   "source": [
    "from mmseg.apis import inference_segmentor\n",
    "img = mmcv.imread('/content/mmsegmentation/segmentation/images/image003-2-roi1.jpg')\n",
    "\n",
    "model.cfg = cfg\n",
    "result = inference_segmentor(model, img)\n",
    "plt.figure(figsize=(8, 6))\n",
    "show_result_pyplot(model, img, result, palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8462ce",
   "metadata": {
    "id": "5d8462ce"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "My MMSegmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
